{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65b5c149-fd19-44c9-8f83-304c56d0f67f",
   "metadata": {},
   "source": [
    "#  Импорт и Клик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3f41729-67d4-4289-a4e8-a3b03c0ff54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import csv\n",
    "\n",
    "import getpass\n",
    "import clickhouse_driver\n",
    "from clickhouse_driver import Client\n",
    "\n",
    "import pytz\n",
    "MSK = pytz.timezone('Europe/Moscow')\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# -----------------------------------------------\n",
    "random_seed = 1234\n",
    "random.seed(random_seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18c17f06-22f7-47c1-9a7d-0b0e0007dc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\"analytic\" password:  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/etc/timezone is deprecated on Debian, and no longer reliable. Ignoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1,)]\n"
     ]
    }
   ],
   "source": [
    "tmp_pass = getpass.getpass(prompt=f'\"analytic\" password: ')\n",
    "client = Client(\n",
    "    host='##.#.##.#', \n",
    "    port=9440,\n",
    "    user='analytic',\n",
    "    password=tmp_pass,\n",
    "    secure=True,\n",
    "    verify = False,\n",
    "    ca_certs='../../clickhouse-prom-certs/ca.pem', \n",
    ")\n",
    "print(client.execute('select 1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660918a2-2b85-414e-a314-d6c4e6eb9b77",
   "metadata": {},
   "source": [
    "# Параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6699343b-1e74-473f-bc86-c837393b4880",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_filename = 'data/result.parquet'\n",
    "fraud_filename = 'data/fraud.json'\n",
    "columns_filename = 'data/columns.json'\n",
    "\n",
    "\n",
    "prom = 'prom2'\n",
    "org_id = '####' # ####\n",
    "\n",
    "date_from_notfraud = '2025-01-09 00:00:00'\n",
    "date_to_notfraud = '2025-03-01 00:00:00'\n",
    "#2025-01-01 - 2025-03-08     ####\n",
    "#2025-01-09 - 2025-03-23  #####\n",
    "\n",
    "partition = 100 # по сколько фродовых сессий упоминать в запросе (чтобы не достигать лимита символов)\n",
    "possibility_to_gather = 0.001 # какую долю от количества сессий в запросе брать в сет\n",
    "max_file_size = 1000000000 # максимальный размер одного файла в байтах\n",
    "max_number_rows = 50000 # максимальное количество сессий записаных во временный список-накопитель\n",
    "str_columns = ['users', 'mouse_by_page', 'scripts_data', 'invalid_pids', 'fingerprint_data_2', 'mouse_movement_data', \n",
    "               'fingerprint_fields', 'ip_data', 'keyboard_data', 'tcp_params', 'iframes_data', 'invalid_canonical_ids', \n",
    "               'forms', 'global_ids_2', 'ip_tags', 'pid_tags', 'url_tags', 'script_tags', 'dynamic_tag_counters']\n",
    "\n",
    "# при препроцессинге в папке будут доп файлы с припиской итерации генерации\n",
    "dataset_notfraud_file_name = 'data/notfraud_rawdata_fromclick' \n",
    "dataset_fraud_file_name = 'data/fraud_rawdata_fromclick'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51082949-39f5-4a64-9856-7869f2546025",
   "metadata": {},
   "source": [
    "# Загрузка фрода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcd8cc74-0f8a-49d3-b4ef-10630bd4d65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fraud_filename, 'r', encoding='utf-8') as file:\n",
    "    fraud_data = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce8acc0-105f-4740-b1d5-9db4e17726b0",
   "metadata": {},
   "source": [
    "# Функции"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e06287d-cbd7-4aa4-af79-f5a83e052c28",
   "metadata": {},
   "source": [
    "## Параметризация запроса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2989576a-407d-4563-ae45-514e93657f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(columns_filename, 'r', encoding='utf-8') as file:\n",
    "    columns = json.load(file)\n",
    "\n",
    "def gen_request(q_where_part: str, prom):\n",
    "    \"\"\"\n",
    "    return q_result, q_template, q_from_part, q_where_part\n",
    "    \"\"\"\n",
    "    \n",
    "    q_template = f\"\"\"\n",
    "    SELECT\n",
    "        {','.join(columns)}\n",
    "    \"\"\"\n",
    "    \n",
    "    q_from_part = f' FROM {prom}.session '   \n",
    "    q_result = q_template + q_from_part + q_where_part\n",
    "    \n",
    "    return q_result, q_template, q_from_part, q_where_part\n",
    "\n",
    "columns = [x[0] for x in client.execute(gen_request(' LIMIT 0', prom)[0], with_column_types=True)[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60bdbd8-5eef-4af5-94c8-d8ad545590ae",
   "metadata": {},
   "source": [
    "## Выгрузка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e107c62-f046-4bb4-80e8-db8d19411d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_worker(sup, columns, str_columns, temp_file_name, oper, output_files):\n",
    "    sup_df = pd.DataFrame(data=sup, columns=columns)\n",
    "                \n",
    "    for str_col in str_columns:\n",
    "        if str_col in sup_df.columns:\n",
    "            sup_df[str_col] = sup_df[str_col].astype(str)\n",
    "\n",
    "    current_filename = temp_file_name+'_'+str(oper)+'.parquet'\n",
    "    new_filename = temp_file_name+'_'+str(oper+1)+'.parquet'\n",
    "\n",
    "    if os.path.exists(current_filename):\n",
    "        if os.path.getsize(current_filename) >= max_file_size:\n",
    "            sup_df.to_parquet(new_filename, engine='pyarrow')\n",
    "            output_files.append(new_filename)\n",
    "            rec = f'\\nОтсечка. Создание нового файла: {new_filename} | {datetime.now().strftime(\"%d-%m-%Y %H:%M:%S.%f\")}'\n",
    "            print(rec)\n",
    "            write_to_file(rec)\n",
    "        else:\n",
    "            temp_data = pd.read_parquet(current_filename)\n",
    "            temp_data = pd.concat([temp_data, sup_df], ignore_index=True)\n",
    "            temp_data.to_parquet(current_filename)\n",
    "            rec = f'Отправка в {current_filename}. Итерация № {oper} | {datetime.now().strftime(\"%d-%m-%Y %H:%M:%S.%f\")}'\n",
    "            print(rec)\n",
    "            write_to_file(rec)\n",
    "            \n",
    "            output_files.append(current_filename)\n",
    "            del temp_data\n",
    "    else:\n",
    "        sup_df.to_parquet(current_filename)\n",
    "        output_files.append(current_filename)\n",
    "        rec = f'Отправка в {current_filename}. Итерация № {oper} | {datetime.now().strftime(\"%d-%m-%Y %H:%M:%S.%f\")}'\n",
    "        print(rec)\n",
    "        write_to_file(rec)\n",
    "    del sup, sup_df\n",
    "\n",
    "\n",
    "def click_extractor(gen_q, \n",
    "                    temp_file_name,\n",
    "                    possibility_to_gather = 0.05,\n",
    "                    max_file_size = 1000000000, \n",
    "                    max_number_rows = 5000,\n",
    "                    needed_users = None):\n",
    "    \"\"\"\n",
    "    gen_q = gen_request\n",
    "    possibility_to_gather - вероятность с которой соберется запись из клика - это рандомизация для больших запросов\n",
    "    temp_file_name - текстовое название файла в который будут скидываться постепенно данные.\n",
    "        От этого файла также будут производные с добавлением номера итерации.\n",
    "    max_file_size - размер файла, после которого будет создаваться новый файл (в байтах)\n",
    "    max_number_rows - количество записей, записанных в датафрейм, после которого будет отправка в файл и создание нового фрейма\n",
    "    \"\"\"\n",
    "    \n",
    "    oper = 1\n",
    "    \n",
    "    sup = []\n",
    "    output_files = []\n",
    "    \n",
    "    rec = f'(click_extractor) Начало извлечения данных из ClickHouse | {datetime.now().strftime(\"%d-%m-%Y %H:%M:%S.%f\")}'\n",
    "    print(rec)\n",
    "    write_to_file(rec)\n",
    "    \n",
    "    request, request_template, _, where = gen_q\n",
    "    \n",
    "    if not needed_users:\n",
    "        needed_users = [x[0] for x in client.execute(f\"SELECT distinct(users.user_id) FROM {prom}.session ARRAY JOIN users.user_id {where}\")]\n",
    "\n",
    "    rec = f'(click_extractor) Количество найденных пользователей: {len(needed_users)}'\n",
    "    print(rec)\n",
    "    write_to_file(rec)\n",
    "    \n",
    "    users = random.sample(needed_users, int(len(needed_users) * possibility_to_gather)) \n",
    "    rec = f'(click_extractor) Количество отобранных пользователей: {len(users)}'\n",
    "    print(rec)\n",
    "    write_to_file(rec)\n",
    "    \n",
    "    if len(users) > partition:\n",
    "        for i in tqdm(range(0, len(users), partition)):\n",
    "            \n",
    "            init_where = 'WHERE ' if where == '' else ' AND '\n",
    "            add_q = f\"\"\" {init_where} length(arrayIntersect(users.user_id,{\"['\"+\"','\".join(users[i:i+partition])+\"']\"}))>0\"\"\"\n",
    "            \n",
    "            sup.extend(client.execute(request+add_q))\n",
    "            if len(sup) >= max_number_rows:\n",
    "                file_worker(sup, columns, str_columns, temp_file_name, oper, output_files)\n",
    "                sup = []\n",
    "                oper+=1\n",
    "\n",
    "            rec = f'(click_extractor) Завершено {min(i + partition, len(users))} из {len(users)}'\n",
    "            print(rec)\n",
    "            write_to_file(rec)\n",
    "            \n",
    "        if len(sup)>0:      # остаточные данные  \n",
    "            file_worker(sup, columns, str_columns, temp_file_name, oper, output_files)\n",
    "            \n",
    "    else:\n",
    "        init_where = 'WHERE ' if where == '' else ' AND '\n",
    "        add_q = f\"\"\"{init_where} length(arrayIntersect(users.user_id,{\"['\"+\"','\".join(users)+\"']\"}))>0\"\"\"\n",
    "\n",
    "        df = client.query_dataframe(request+add_q)\n",
    "        for i in str_columns:\n",
    "            if i in df.columns:\n",
    "                df[i]=df[i].astype(str)\n",
    "            \n",
    "        filename = temp_file_name+'_'+str(oper)+'.parquet'\n",
    "        df.to_parquet(filename)\n",
    "        output_files.append(filename)\n",
    "        \n",
    "        del df\n",
    "    \n",
    "    rec = f'(click_extractor) Завершение: {datetime.now().strftime(\"%d-%m-%Y %H:%M:%S.%f\")}'\n",
    "    print(rec)\n",
    "    write_to_file(rec)\n",
    "    \n",
    "    rec = f'(click_extractor) Файлы: {output_files}'\n",
    "    print(rec)\n",
    "    write_to_file(rec)\n",
    "        \n",
    "    return set(output_files)\n",
    "\n",
    "\n",
    "def get_raw_dataset(gen_request, \n",
    "                    download_notfraud,\n",
    "                    date_from_notfraud,\n",
    "                    date_to_notfraud,\n",
    "                    download_fraud,\n",
    "                    possibility_to_gather,\n",
    "                    fraud_users):\n",
    "    \n",
    "    \"\"\"\n",
    "    gen_request - макет запроса в ClickHouse в виде инстанции функции\n",
    "    download_notfraud - bool - загружать нефрод или нет\n",
    "    date_from_notfraud - дата начала загрузки нефрода (форма: '%Y-%m-%d %H:%M:%S')\n",
    "    date_to_notfraud - дата начала загрузки нефрода (форма: '%Y-%m-%d %H:%M:%S')\n",
    "    download_fraud - bool - загружать фрод или нет\n",
    "    \"\"\"\n",
    "\n",
    "    global prom, fraud_filename \n",
    "\n",
    "    date_from_notfraud_loc = int((MSK.localize(datetime.strptime(date_from_notfraud,'%Y-%m-%d %H:%M:%S'))).timestamp())\n",
    "    date_to_notfraud_loc = int((MSK.localize(datetime.strptime(date_to_notfraud,'%Y-%m-%d %H:%M:%S'))).timestamp()) \n",
    "    \n",
    "    if not download_notfraud and not download_fraud:\n",
    "        rec = 'Указаны download_notfraud и download_fraud как False - ошибка.'\n",
    "        print(rec)\n",
    "        write_to_file(rec)\n",
    "        return None\n",
    "    \n",
    "    oper = 1\n",
    "    files = []\n",
    "    \n",
    "    rec = f'(get_dataset) Время начала работы функции | {datetime.now().strftime(\"%Y.%m.%d.%H.%M\")}'\n",
    "    print(rec)\n",
    "    write_to_file(rec)\n",
    "    \n",
    "    if download_fraud and fraud_users:\n",
    "        rec = f'(get_dataset) Загрузка фродовых сессий | {datetime.now().strftime(\"%Y.%m.%d.%H.%M\")}'\n",
    "        print(rec)\n",
    "        write_to_file(rec)\n",
    "        \n",
    "        fraud_files = click_extractor(gen_request(f\"WHERE org_id = '{org_id}'\", prom=prom), \n",
    "                                      dataset_fraud_file_name,\n",
    "                                      possibility_to_gather = 1,\n",
    "                                      max_file_size = max_file_size, \n",
    "                                      max_number_rows = max_number_rows,\n",
    "                                      needed_users = fraud_users)\n",
    "        files.extend(fraud_files)\n",
    "                    \n",
    "    if download_notfraud:\n",
    "        rec = f'(get_dataset) Загрузка нефродовых сессий | {datetime.now().strftime(\"%Y.%m.%d.%H.%M\")}'\n",
    "        print(rec)\n",
    "        write_to_file(rec)\n",
    "        q_where_part = f\"\"\"WHERE \n",
    "                            begin_at >= {date_from_notfraud_loc} AND \n",
    "                            begin_at < {date_to_notfraud_loc} AND \n",
    "                            org_id = '{org_id}'\"\"\"\n",
    "\n",
    "        \n",
    "        notfraud_files = click_extractor(gen_request(q_where_part, prom=prom), \n",
    "                                         dataset_notfraud_file_name,\n",
    "                                         possibility_to_gather = possibility_to_gather,\n",
    "                                         max_file_size = max_file_size, \n",
    "                                         max_number_rows = max_number_rows)\n",
    "        files.extend(notfraud_files)\n",
    "        \n",
    "    res_df = pd.DataFrame()\n",
    "    \n",
    "    for i in files:\n",
    "        temp_data = pd.read_parquet(i)\n",
    "        res_df = pd.concat([res_df, temp_data], ignore_index=True)\n",
    "    \n",
    "    return res_df, files\n",
    "\n",
    "\n",
    "def write_to_file(record, name: str = 'log.csv'):\n",
    "    with open(name, 'a', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f, delimiter=';', dialect='excel')\n",
    "        writer.writerow([datetime.now()] + [record])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2519ad06-7b9b-4251-8c72-c2cf3a4383d8",
   "metadata": {},
   "source": [
    "# Исполнение выгрузки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cda1f150-13ea-4190-b3e8-0ecb1cd74ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(get_dataset) Время начала работы функции | 2025.03.27.14.30\n",
      "(get_dataset) Загрузка фродовых сессий | 2025.03.27.14.30\n",
      "(click_extractor) Начало извлечения данных из ClickHouse | 27-03-2025 14:30:59.625823\n",
      "(click_extractor) Количество найденных пользователей: 1\n",
      "(click_extractor) Количество отобранных пользователей: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# with open(fraud_filename, 'r') as file:\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m#     fraud_users = json.load(file)['fraud_users']\u001b[39;00m\n\u001b[32m      7\u001b[39m fraud_users = [\u001b[33m'\u001b[39m\u001b[33mea70c77db2e7d793771972aad94377ba056da30e80c346fa10e52eef87d1d203\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m df_from_click, files = \u001b[43mget_raw_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m                                       \u001b[49m\u001b[43mdownload_notfraud\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m                                       \u001b[49m\u001b[43mdate_from_notfraud\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate_from_notfraud\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m                                       \u001b[49m\u001b[43mdate_to_notfraud\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate_to_notfraud\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m                                       \u001b[49m\u001b[43mdownload_fraud\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m                                       \u001b[49m\u001b[43mpossibility_to_gather\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpossibility_to_gather\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m                                       \u001b[49m\u001b[43mfraud_users\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfraud_users\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 159\u001b[39m, in \u001b[36mget_raw_dataset\u001b[39m\u001b[34m(gen_request, download_notfraud, date_from_notfraud, date_to_notfraud, download_fraud, possibility_to_gather, fraud_users)\u001b[39m\n\u001b[32m    156\u001b[39m     \u001b[38;5;28mprint\u001b[39m(rec)\n\u001b[32m    157\u001b[39m     write_to_file(rec)\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     fraud_files = \u001b[43mclick_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen_request\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWHERE org_id = \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43morg_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprom\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprom\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m                                  \u001b[49m\u001b[43mdataset_fraud_file_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m                                  \u001b[49m\u001b[43mpossibility_to_gather\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m                                  \u001b[49m\u001b[43mmax_file_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_file_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m                                  \u001b[49m\u001b[43mmax_number_rows\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_number_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m                                  \u001b[49m\u001b[43mneeded_users\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfraud_users\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m     files.extend(fraud_files)\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m download_notfraud:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 98\u001b[39m, in \u001b[36mclick_extractor\u001b[39m\u001b[34m(gen_q, temp_file_name, possibility_to_gather, max_file_size, max_number_rows, needed_users)\u001b[39m\n\u001b[32m     95\u001b[39m init_where = \u001b[33m'\u001b[39m\u001b[33mWHERE \u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m where == \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m AND \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     96\u001b[39m add_q = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minit_where\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m length(arrayIntersect(users.user_id,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m+\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m,\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m.join(users)+\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m))>0\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m df = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m+\u001b[49m\u001b[43madd_q\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m str_columns:\n\u001b[32m    100\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m df.columns:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lib/python3.12/site-packages/clickhouse_driver/client.py:491\u001b[39m, in \u001b[36mClient.query_dataframe\u001b[39m\u001b[34m(self, query, params, external_tables, query_id, settings, replace_nonwords)\u001b[39m\n\u001b[32m    488\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m    489\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mExtras for NumPy must be installed\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m491\u001b[39m data, columns = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumnar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_column_types\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexternal_tables\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexternal_tables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m    \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m=\u001b[49m\u001b[43msettings\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    497\u001b[39m columns = [name \u001b[38;5;28;01mfor\u001b[39;00m name, type_ \u001b[38;5;129;01min\u001b[39;00m columns]\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m replace_nonwords:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lib/python3.12/site-packages/clickhouse_driver/client.py:382\u001b[39m, in \u001b[36mClient.execute\u001b[39m\u001b[34m(self, query, params, with_column_types, external_tables, query_id, settings, types_check, columnar)\u001b[39m\n\u001b[32m    376\u001b[39m     rv = \u001b[38;5;28mself\u001b[39m.process_insert_query(\n\u001b[32m    377\u001b[39m         query, params, external_tables=external_tables,\n\u001b[32m    378\u001b[39m         query_id=query_id, types_check=types_check,\n\u001b[32m    379\u001b[39m         columnar=columnar\n\u001b[32m    380\u001b[39m     )\n\u001b[32m    381\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m     rv = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocess_ordinary_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_column_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwith_column_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexternal_tables\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexternal_tables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes_check\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtypes_check\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumnar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumnar\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[38;5;28mself\u001b[39m.last_query.store_elapsed(time() - start_time)\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m rv\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lib/python3.12/site-packages/clickhouse_driver/client.py:580\u001b[39m, in \u001b[36mClient.process_ordinary_query\u001b[39m\u001b[34m(self, query, params, with_column_types, external_tables, query_id, types_check, columnar)\u001b[39m\n\u001b[32m    577\u001b[39m \u001b[38;5;28mself\u001b[39m.connection.send_query(query, query_id=query_id, params=params)\n\u001b[32m    578\u001b[39m \u001b[38;5;28mself\u001b[39m.connection.send_external_tables(external_tables,\n\u001b[32m    579\u001b[39m                                      types_check=types_check)\n\u001b[32m--> \u001b[39m\u001b[32m580\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreceive_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwith_column_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwith_column_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    581\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mcolumnar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumnar\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lib/python3.12/site-packages/clickhouse_driver/client.py:213\u001b[39m, in \u001b[36mClient.receive_result\u001b[39m\u001b[34m(self, with_column_types, progress, columnar)\u001b[39m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    210\u001b[39m     result = \u001b[38;5;28mself\u001b[39m.query_result_cls(\n\u001b[32m    211\u001b[39m         gen, with_column_types=with_column_types, columnar=columnar\n\u001b[32m    212\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lib/python3.12/site-packages/clickhouse_driver/result.py:50\u001b[39m, in \u001b[36mQueryResult.get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_result\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     46\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[33;03m    :return: stored query result.\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpacket\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpacket_generator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpacket\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lib/python3.12/site-packages/clickhouse_driver/client.py:229\u001b[39m, in \u001b[36mClient.packet_generator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    228\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m         packet = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreceive_packet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    230\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m packet:\n\u001b[32m    231\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lib/python3.12/site-packages/clickhouse_driver/client.py:243\u001b[39m, in \u001b[36mClient.receive_packet\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreceive_packet\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m     packet = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreceive_packet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m packet.type == ServerPacketTypes.EXCEPTION:\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m packet.exception\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lib/python3.12/site-packages/clickhouse_driver/connection.py:574\u001b[39m, in \u001b[36mConnection.receive_packet\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreceive_packet\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    572\u001b[39m     packet = Packet()\n\u001b[32m--> \u001b[39m\u001b[32m574\u001b[39m     packet.type = packet_type = \u001b[43mread_varint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    576\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m packet_type == ServerPacketTypes.DATA:\n\u001b[32m    577\u001b[39m         packet.block = \u001b[38;5;28mself\u001b[39m.receive_data(may_be_use_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mclickhouse_driver/varint.pyx:62\u001b[39m, in \u001b[36mclickhouse_driver.varint.read_varint\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mclickhouse_driver/bufferedreader.pyx:55\u001b[39m, in \u001b[36mclickhouse_driver.bufferedreader.BufferedReader.read_one\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mclickhouse_driver/bufferedreader.pyx:237\u001b[39m, in \u001b[36mclickhouse_driver.bufferedreader.BufferedSocketReader.read_into_buffer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lib/python3.12/ssl.py:1252\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1249\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1250\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1251\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1252\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1254\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lib/python3.12/ssl.py:1104\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1104\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1105\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1106\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "df_from_click, files = get_raw_dataset(gen_request, \n",
    "                                       download_notfraud=False,\n",
    "                                       date_from_notfraud = date_from_notfraud,\n",
    "                                       date_to_notfraud = date_to_notfraud,\n",
    "                                       download_fraud = True,\n",
    "                                       possibility_to_gather = possibility_to_gather,\n",
    "                                       fraud_users = fraud_users)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
