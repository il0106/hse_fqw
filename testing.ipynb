{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a94ea8c-b750-4f39-bce3-47990cc8c7cf",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c2067a7-0e29-4d25-bbad-e4c4454d63af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import recall_score, classification_report, confusion_matrix, make_scorer\n",
    "from sklearn.inspection import permutation_importance\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def set_all_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "\n",
    "def log(record, name: str = 'log__testing.csv'):\n",
    "    with open(name, 'a', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f, delimiter=';', dialect='excel')\n",
    "        writer.writerow([datetime.now()] + [record])\n",
    "\n",
    "\n",
    "random_seed = 1234\n",
    "set_all_seeds(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ca21cb-7e70-4d98-b836-8335354e3d4a",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7831e86d-a09d-4e6c-9a25-3085d59a2dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'data/dataset_after_eda.parquet'\n",
    "target_column = 'target'\n",
    "datetime_column = '17'\n",
    "time_split = '2025-04-15'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b152610f-1ead-4e8c-a937-62dec17f040f",
   "metadata": {},
   "source": [
    "# Testing process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57732ae8-c971-41c1-a325-ed17eee0ef48",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f79dd073-fe63-42a6-be9e-38d7cd5a4e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_report(y_true, y_pred, model_name = '_'):\n",
    "    print('\\n---------------------------------------------------------------')\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Test data length: {len(y_true)}\")\n",
    "    print(f\"Fraud sessions in test data: {sum(y_true)}\")\n",
    "    \n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    if len(set(y_true))>1:\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()        \n",
    "        \n",
    "        print(f'\\nTN: {tn}')\n",
    "        print(f'FP: {fp}')\n",
    "        print(f'FN: {fn}')\n",
    "        print(f'TP: {tp}')   \n",
    "        \n",
    "        fpr = fp/(fp+tn) \n",
    "        fnr = fn/(fn+tp)\n",
    "        print('False Negative Rate = ',fnr)\n",
    "        print('False Positive Rate = ',fpr)\n",
    "    else:\n",
    "        print('One label, fpr is out function scope.')\n",
    "        \n",
    "\n",
    "def find_threshold_fpr(y_true, y_pred_proba, target_fpr):\n",
    "    sorted_indices = np.argsort(y_pred_proba)[::-1]\n",
    "    y_true_sorted = y_true[sorted_indices]\n",
    "    y_pred_proba_sorted = y_pred_proba[sorted_indices]\n",
    "    false_pos = 0.0\n",
    "    threshold = 0.0\n",
    "    for i in range(len(y_true_sorted)):\n",
    "        if y_true_sorted[i] == 0:\n",
    "            false_pos += 1\n",
    "        if false_pos / len(y_true_sorted) >= target_fpr:\n",
    "            threshold = y_pred_proba_sorted[i]\n",
    "            break\n",
    "    return threshold\n",
    "\n",
    "\n",
    "def get_recall_on_fpr(y_true, y_proba, target_fpr):\n",
    "    threshold = find_threshold_fpr(y_true, y_proba, target_fpr)\n",
    "    y_pred_binary = np.where(y_proba >= threshold, 1, 0)\n",
    "    score = recall_score(y_true, y_pred_binary)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred_binary).ravel()\n",
    "    fpr = fp / (fp + tn)\n",
    "    if fpr > target_fpr * 2:\n",
    "        return 0\n",
    "    return score\n",
    "\n",
    "\n",
    "def train_test_split_df(X, \n",
    "                        y, \n",
    "                        class_probabilities={0:0.2,1:0.2}, \n",
    "                        shuffle=True,\n",
    "                        random_state=random_seed):\n",
    "    \"\"\"\n",
    "    A dictionary of shares is used with each class. These data shares are recorded for sample in the test set.\n",
    "    Example: {0:0.02, 1:0.02}\n",
    "    return:\n",
    "        X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    \n",
    "    if random_state is not None:\n",
    "        random.seed(random_state)\n",
    "\n",
    "    class_indices = defaultdict(list)\n",
    "\n",
    "    for idx, label in enumerate(y.to_numpy()):\n",
    "        class_indices[label].append(idx)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = [], [], [], []\n",
    "\n",
    "    for label, prob in class_probabilities.items():\n",
    "        indices = class_indices[label]\n",
    "        split_index = int((1 - prob) * len(indices))\n",
    "        if shuffle:\n",
    "            random.shuffle(indices)\n",
    "\n",
    "        train_indices, test_indices = indices[:split_index], indices[split_index:]\n",
    "\n",
    "        X_train.append(X.iloc[train_indices])\n",
    "        X_test.append(X.iloc[test_indices])\n",
    "        y_train.append(y.iloc[train_indices])\n",
    "        y_test.append(y.iloc[test_indices]) \n",
    "        \n",
    "    X_train = pd.concat([*X_train],ignore_index=True)\n",
    "    X_test = pd.concat([*X_test],ignore_index=True)\n",
    "    y_train = pd.concat([*y_train],ignore_index=True)\n",
    "    y_test = pd.concat([*y_test],ignore_index=True)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "\n",
    "def make_test(df, target_column, datetime_column, split_date, class_0_share=0.1):\n",
    "    \n",
    "    df[datetime_column] = pd.to_datetime(df[datetime_column])\n",
    "    \n",
    "    dt_train_fraud = df[(df[datetime_column] < split_date) & (df[target_column]==1)]\n",
    "    df_test_fraud = df[(df[datetime_column] >= split_date) & (df[target_column]==1)]\n",
    "                        \n",
    "    df_test_clear = df[df[target_column]==0].sample(frac=class_0_share, random_state=random_seed)\n",
    "    df_train_clear = df[df[target_column]==0].drop(df_test_clear.index)\n",
    "    \n",
    "    train = pd.concat([dt_train_fraud, df_train_clear],ignore_index=True).drop(columns=[datetime_column])\n",
    "    test = pd.concat([df_test_fraud, df_test_clear],ignore_index=True).drop(columns=[datetime_column])\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd5d3dc-7f8c-44fe-934d-ce9f3a0a4c9e",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02d20453-5c3f-49a9-baf9-b9e6ab8e89ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(dataset_path)\n",
    "cols_to_drop = ['252', '414', '127', '228', '398', '226', '209', '109', '396', '243', '380', '98', '271', '268', '194', '400', '394', '429', '120', '239', '215', '181', '180', '416', '67', '256', '151', '419', '240', '158', '34', '164', '258', '424', '415', '168', '438', '283', '403', '152', '102', '60', '129', '225', '169', '409', '83', '26', '406', '413', '200', '244', '247', '430', '266', '96', '410', '161', '251']\n",
    "strict_perm = ['142','389','390']\n",
    "cols_to_drop += strict_perm\n",
    "df = df.drop(columns=cols_to_drop)\n",
    "train_val_df, test_df = make_test(df, \n",
    "                                  target_column, \n",
    "                                  datetime_column, \n",
    "                                  pd.Timestamp(time_split), \n",
    "                                  class_0_share=0.1)\n",
    "X_train, X_val, y_train, y_val = train_test_split_df(train_val_df.drop(columns=[target_column]),\n",
    "                                                     train_val_df[target_column], \n",
    "                                                     class_probabilities={0:0.1, 1:0.1}, \n",
    "                                                     shuffle=True,\n",
    "                                                     random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3deab64-2789-40b6-bb2e-cddb40da948f",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3a1ff9b-2f86-493b-9530-fcde92e67b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------\n",
      "Model: Final model testing\n",
      "Test data length: 39730\n",
      "Fraud sessions in test data: 286.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     39444\n",
      "         1.0       0.66      0.72      0.69       286\n",
      "\n",
      "    accuracy                           1.00     39730\n",
      "   macro avg       0.83      0.86      0.84     39730\n",
      "weighted avg       1.00      1.00      1.00     39730\n",
      "\n",
      "\n",
      "TN: 39339\n",
      "FP: 105\n",
      "FN: 81\n",
      "TP: 205\n",
      "False Negative Rate =  0.28321678321678323\n",
      "False Positive Rate =  0.00266200182537268\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 190, 'max_depth': 7, 'learning_rate': 0.557, 'subsample': 1.0, 'colsample_bytree': 0.8, 'scale_pos_weight': 3497.0, 'reg_alpha': 4.16, 'reg_lambda': 8.61, 'gamma': 0.37}\n",
    "\n",
    "model = xgb.XGBClassifier(**params, random_state=random_seed)\n",
    "model.fit(train_val_df.drop(columns=[target_column]),\n",
    "          train_val_df[target_column])\n",
    "y_pred = [x>=0.5 for x in model.predict_proba(test_df.drop(columns=[target_column]))[:, 1]]\n",
    "model_report(test_df[target_column], y_pred, 'Final model testing')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
